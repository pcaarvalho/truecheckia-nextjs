import OpenAI from 'openai'
import { AnalysisIndicator, SuspiciousPart } from '@/app/types/analysis'
import { AI_CONFIG, validateOpenAIConfig, getEnvironmentConfig, CostTracker } from './ai-config'

// Get environment-specific configuration
const config = getEnvironmentConfig()

// Validate configuration on startup
const configValidation = validateOpenAIConfig()
if (!configValidation.isValid) {
  console.error('OpenAI configuration errors:', configValidation.errors)
}

// OpenAI client configuration
const openai = new OpenAI({
  apiKey: config.openai.apiKey,
  organization: config.openai.organization,
  timeout: config.openai.timeout,
})

// Cache for storing embeddings and analysis results
const analysisCache = new Map<string, any>()
const CACHE_EXPIRY = config.cache.expiryMinutes * 60 * 1000

// Cost tracking
let dailyCostTracker = { date: new Date().toDateString(), cost: 0 }

interface AIDetectionResult {
  aiScore: number
  confidence: 'LOW' | 'MEDIUM' | 'HIGH'
  isAiGenerated: boolean
  indicators: AnalysisIndicator[]
  explanation: string
  suspiciousParts: SuspiciousPart[]
  processingTime: number
  wordCount: number
  charCount: number
}

interface TextMetrics {
  wordCount: number
  charCount: number
  sentences: string[]
  avgSentenceLength: number
  sentenceLengthVariance: number
  vocabularyRatio: number
  uniqueWords: Set<string>
  words: string[]
}

/**
 * Extracts basic text metrics for analysis
 */
function extractTextMetrics(text: string): TextMetrics {
  const words = text.toLowerCase().split(/\s+/).filter(word => word.length > 0)
  const uniqueWords = new Set(words)
  const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0)
  
  const avgSentenceLength = sentences.reduce((sum, s) => sum + s.trim().length, 0) / sentences.length
  const sentenceLengthVariance = sentences.reduce((sum, s) => {
    const diff = s.trim().length - avgSentenceLength
    return sum + (diff * diff)
  }, 0) / sentences.length

  return {
    wordCount: words.length,
    charCount: text.length,
    sentences,
    avgSentenceLength,
    sentenceLengthVariance,
    vocabularyRatio: uniqueWords.size / words.length,
    uniqueWords,
    words
  }
}

/**
 * Tracks and validates daily costs
 */
function trackCost(estimatedCost: number): boolean {
  const today = new Date().toDateString()
  
  if (dailyCostTracker.date !== today) {
    dailyCostTracker = { date: today, cost: 0 }
  }
  
  if (dailyCostTracker.cost + estimatedCost > config.costOptimization.maxDailyCost) {
    console.warn(`Daily cost limit approaching: $${dailyCostTracker.cost + estimatedCost}`)
    return false
  }
  
  dailyCostTracker.cost += estimatedCost
  
  if (dailyCostTracker.cost > config.costOptimization.alertThreshold) {
    console.warn(`Daily cost alert: $${dailyCostTracker.cost}`)
  }
  
  return true
}

/**
 * Analyzes text using GPT-4 for AI detection patterns
 */
async function analyzeWithGPT4(text: string, language: string): Promise<{
  aiProbability: number
  reasoning: string
  patterns: string[]
  cost: number
}> {
  // Check cost limits
  const estimatedCost = CostTracker.estimateAnalysisCost(text.length)
  
  if (!trackCost(estimatedCost)) {
    throw new Error('Daily cost limit exceeded')
  }

  // Choose model based on cost optimization
  const model = CostTracker.shouldUseFallbackModel(text.length) 
    ? config.openai.models.fallback 
    : config.openai.models.chat

  const prompt = `You are an expert AI text detector. Analyze the following text and determine if it was likely generated by AI.

Consider these factors:
1. Repetitive patterns or phrases
2. Overly formal or structured language
3. Lack of personal voice or emotion
4. Generic expressions and clichés
5. Uniform sentence structures
6. Perfect grammar without natural imperfections
7. Predictable content flow
8. Absence of unique insights or personal experiences
9. Statistical anomalies in word usage
10. Consistent tone without natural variation

Text to analyze (language: ${language}):
"${text}"

Respond with a JSON object containing:
- aiProbability: number between 0-100 (probability of AI generation)
- reasoning: brief explanation of your analysis (max 200 characters)
- patterns: array of specific patterns that suggest AI generation (max 5 items)

Be objective and provide specific evidence for your assessment.`

  try {
    const response = await openai.chat.completions.create({
      model,
      messages: [{ role: 'user', content: prompt }],
      temperature: config.openai.temperature,
      max_tokens: config.openai.maxTokens.analysis,
    })

    const content = response.choices[0]?.message?.content
    if (!content) {
      throw new Error('No response from OpenAI')
    }

    // Try to parse JSON response
    try {
      const parsed = JSON.parse(content)
      return {
        ...parsed,
        cost: estimatedCost
      }
    } catch (parseError) {
      // Fallback if JSON parsing fails
      return {
        aiProbability: 50,
        reasoning: content.substring(0, 200),
        patterns: [],
        cost: estimatedCost
      }
    }
  } catch (error) {
    if (config.monitoring.logErrors) {
      console.error('GPT-4 analysis failed:', error)
    }
    
    if (!config.errorHandling.enableFallback) {
      throw error
    }
    
    // Return fallback analysis
    return {
      aiProbability: config.errorHandling.defaultScore,
      reasoning: 'Analysis unavailable due to API error',
      patterns: [],
      cost: 0
    }
  }
}

/**
 * Generates embeddings for the text to compare against known AI patterns
 */
async function generateEmbeddings(text: string): Promise<{ embeddings: number[]; cost: number }> {
  try {
    // Truncate text if too long for embedding model
    const truncatedText = text.length > config.openai.maxTokens.embedding * 4 
      ? text.substring(0, config.openai.maxTokens.embedding * 4)
      : text

    const embeddingCost = CostTracker.estimateAnalysisCost(truncatedText.length, config.openai.models.embedding)
    
    if (!trackCost(embeddingCost)) {
      return { embeddings: [], cost: 0 }
    }

    const response = await openai.embeddings.create({
      model: config.openai.models.embedding,
      input: truncatedText,
    })

    return {
      embeddings: response.data[0].embedding,
      cost: embeddingCost
    }
  } catch (error) {
    if (config.monitoring.logErrors) {
      console.error('Embedding generation failed:', error)
    }
    return { embeddings: [], cost: 0 }
  }
}

/**
 * Performs statistical analysis on text characteristics
 */
function performStatisticalAnalysis(metrics: TextMetrics): {
  indicators: AnalysisIndicator[]
  suspiciousParts: SuspiciousPart[]
  statisticalScore: number
} {
  const indicators: AnalysisIndicator[] = []
  const suspiciousParts: SuspiciousPart[] = []
  let statisticalScore = 0

  // Check vocabulary diversity
  if (metrics.vocabularyRatio < config.statistical.vocabularyRatioThreshold && metrics.wordCount > 50) {
    statisticalScore += 25
    indicators.push({
      type: 'low_vocabulary_diversity',
      description: 'Low vocabulary diversity suggests repetitive AI patterns',
      severity: 'high'
    })
  }

  // Check sentence length consistency
  if (metrics.sentenceLengthVariance < config.statistical.sentenceVarianceThreshold && metrics.sentences.length > 3) {
    statisticalScore += 20
    indicators.push({
      type: 'uniform_sentence_length',
      description: 'Uniform sentence lengths indicate potential AI generation',
      severity: 'high'
    })
  }

  // Check for common AI transition phrases using configured list
  const foundAiPhrases = config.statistical.aiPhrases.filter(phrase => 
    metrics.words.join(' ').includes(phrase)
  )

  if (foundAiPhrases.length > config.statistical.commonPhrasesThreshold) {
    const score = Math.min(foundAiPhrases.length * 5, 25) // Up to 25 points
    statisticalScore += score
    indicators.push({
      type: 'ai_transition_phrases',
      description: `Contains ${foundAiPhrases.length} AI-typical transition phrases`,
      severity: foundAiPhrases.length > 4 ? 'high' : 'medium'
    })

    // Add suspicious parts (limit to top 3)
    foundAiPhrases.slice(0, 3).forEach(phrase => {
      suspiciousParts.push({
        text: phrase,
        score: 75 + (foundAiPhrases.length * 2),
        reason: 'Common AI-generated transition phrase'
      })
    })
  }

  // Check for overly perfect punctuation
  const punctuationPattern = /[.!?][A-Z]/g
  const punctuationMatches = (metrics.words.join(' ').match(punctuationPattern) || []).length
  const expectedPunctuation = metrics.sentences.length - 1
  
  if (Math.abs(punctuationMatches - expectedPunctuation) < 2 && metrics.sentences.length > 5) {
    statisticalScore += 10
    indicators.push({
      type: 'perfect_punctuation',
      description: 'Overly consistent punctuation patterns',
      severity: 'low'
    })
  }

  // Additional statistical checks
  
  // Check for unusual word length distribution
  const avgWordLength = metrics.words.reduce((sum, word) => sum + word.length, 0) / metrics.words.length
  if (avgWordLength > 6.5 || avgWordLength < 3.5) {
    statisticalScore += 8
    indicators.push({
      type: 'unusual_word_length',
      description: `Unusual average word length: ${avgWordLength.toFixed(1)} characters`,
      severity: 'low'
    })
  }

  // Check for excessive use of connecting words
  const connectingWords = ['and', 'but', 'or', 'so', 'because', 'however', 'therefore', 'e', 'mas', 'ou', 'então', 'porque', 'entretanto', 'portanto']
  const connectingWordsCount = metrics.words.filter(word => connectingWords.includes(word)).length
  const connectingWordsRatio = connectingWordsCount / metrics.words.length
  
  if (connectingWordsRatio > 0.15) {
    statisticalScore += 12
    indicators.push({
      type: 'excessive_connecting_words',
      description: 'High frequency of connecting words typical of AI text',
      severity: 'medium'
    })
  }

  return {
    indicators,
    suspiciousParts,
    statisticalScore: Math.min(statisticalScore, 100)
  }
}

/**
 * Combines multiple detection methods for final scoring
 */
function combineAnalysisResults(
  gpt4Analysis: { aiProbability: number; reasoning: string; patterns: string[]; cost: number },
  statisticalAnalysis: { indicators: AnalysisIndicator[]; suspiciousParts: SuspiciousPart[]; statisticalScore: number },
  embeddings: { embeddings: number[]; cost: number },
  metrics: TextMetrics
): {
  finalScore: number
  confidence: 'LOW' | 'MEDIUM' | 'HIGH'
  explanation: string
  allIndicators: AnalysisIndicator[]
  allSuspiciousParts: SuspiciousPart[]
  totalCost: number
} {
  // Use configured weights
  const finalScore = (gpt4Analysis.aiProbability * config.weights.gpt4Analysis) + 
                    (statisticalAnalysis.statisticalScore * config.weights.statisticalAnalysis)

  // Determine confidence based on agreement between methods
  const scoreDifference = Math.abs(gpt4Analysis.aiProbability - statisticalAnalysis.statisticalScore)
  let confidence: 'LOW' | 'MEDIUM' | 'HIGH' = 'MEDIUM'
  
  if (scoreDifference < config.thresholds.scoreDifferenceForHighConfidence) {
    confidence = 'HIGH'
  } else if (scoreDifference > 40) {
    confidence = 'LOW'
  }

  // Adjust confidence based on text length
  if (metrics.wordCount < 30) {
    confidence = confidence === 'HIGH' ? 'MEDIUM' : 'LOW'
  }

  // Add GPT-4 specific indicators
  const gpt4Indicators: AnalysisIndicator[] = gpt4Analysis.patterns.slice(0, 5).map(pattern => ({
    type: 'ai_detected_pattern',
    description: `AI model detected: ${pattern}`,
    severity: 'medium' as const
  }))

  // Create comprehensive explanation
  const agreementText = scoreDifference < config.thresholds.scoreDifferenceForHighConfidence 
    ? 'confirms' 
    : scoreDifference > 40 
      ? 'contradicts' 
      : 'partially supports'
  
  const explanation = `AI Detection: ${Math.round(finalScore)}% probability. ${gpt4Analysis.reasoning} Statistical analysis ${agreementText} these findings. Text: ${metrics.wordCount} words, ${metrics.vocabularyRatio.toFixed(2)} vocabulary diversity.`

  return {
    finalScore: Math.round(finalScore * 100) / 100,
    confidence,
    explanation,
    allIndicators: [...statisticalAnalysis.indicators, ...gpt4Indicators],
    allSuspiciousParts: statisticalAnalysis.suspiciousParts,
    totalCost: gpt4Analysis.cost + embeddings.cost
  }
}

/**
 * Main AI detection function with comprehensive analysis
 */
export async function detectAIContent(text: string, language: string = 'pt'): Promise<AIDetectionResult & { cost?: number }> {
  const startTime = Date.now()
  
  // Validate input
  if (!text || text.trim().length < config.thresholds.minimumTextLength) {
    throw new Error(`Text must be at least ${config.thresholds.minimumTextLength} characters long`)
  }
  
  if (text.length > config.thresholds.maximumTextLength) {
    throw new Error(`Text must be less than ${config.thresholds.maximumTextLength} characters`)
  }
  
  // Check cache first if enabled
  const cacheKey = config.cache.enabled 
    ? `${text.substring(0, config.cache.keyLength)}_${language}`
    : null
    
  if (cacheKey && config.cache.enabled) {
    const cached = analysisCache.get(cacheKey)
    if (cached && Date.now() - cached.timestamp < CACHE_EXPIRY) {
      if (config.monitoring.logAnalysisResults) {
        console.log('Cache hit for analysis')
      }
      return {
        ...cached.result,
        processingTime: Date.now() - startTime
      }
    }
  }

  try {
    // Extract basic metrics
    const metrics = extractTextMetrics(text)

    // Always run statistical analysis (free)
    const statisticalAnalysis = performStatisticalAnalysis(metrics)
    
    // Run GPT-4 analysis and embeddings in parallel if API key is available
    let gpt4Analysis: { aiProbability: number; reasoning: string; patterns: string[]; cost: number } | null = null
    let embeddings: { embeddings: number[]; cost: number } | null = null
    
    if (config.openai.apiKey) {
      [gpt4Analysis, embeddings] = await Promise.all([
        analyzeWithGPT4(text, language),
        generateEmbeddings(text)
      ])
    } else {
      embeddings = { embeddings: [], cost: 0 }
    }

    // Combine all results
    const combined = combineAnalysisResults(
      gpt4Analysis || { aiProbability: config.errorHandling.defaultScore, reasoning: 'GPT-4 analysis not available', patterns: [], cost: 0 },
      statisticalAnalysis,
      embeddings || { embeddings: [], cost: 0 },
      metrics
    )

    const result: AIDetectionResult & { cost?: number } = {
      aiScore: combined.finalScore,
      confidence: combined.confidence,
      isAiGenerated: combined.finalScore > config.thresholds.aiGenerated,
      indicators: combined.allIndicators,
      explanation: combined.explanation,
      suspiciousParts: combined.allSuspiciousParts,
      processingTime: Date.now() - startTime,
      wordCount: metrics.wordCount,
      charCount: metrics.charCount,
      cost: config.monitoring.trackCosts ? combined.totalCost : undefined
    }

    // Cache the result if enabled
    if (cacheKey && config.cache.enabled) {
      // Clean cache if it's getting too large
      if (analysisCache.size > config.cache.maxEntries) {
        const oldestKey = analysisCache.keys().next().value
        if (oldestKey) {
          analysisCache.delete(oldestKey)
        }
      }
      
      analysisCache.set(cacheKey, {
        result,
        timestamp: Date.now()
      })
    }

    if (config.monitoring.logAnalysisResults) {
      console.log('Analysis completed:', {
        score: result.aiScore,
        confidence: result.confidence,
        indicators: result.indicators.length,
        cost: result.cost,
        processingTime: result.processingTime
      })
    }

    return result

  } catch (error) {
    if (config.monitoring.logErrors) {
      console.error('AI detection failed:', error)
    }
    
    if (!config.errorHandling.enableFallback) {
      throw error
    }
    
    // Fallback to basic statistical analysis only
    const metrics = extractTextMetrics(text)
    const statisticalAnalysis = performStatisticalAnalysis(metrics)
    
    return {
      aiScore: config.errorHandling.returnPartialResults 
        ? statisticalAnalysis.statisticalScore
        : config.errorHandling.defaultScore,
      confidence: 'LOW',
      isAiGenerated: (config.errorHandling.returnPartialResults 
        ? statisticalAnalysis.statisticalScore 
        : config.errorHandling.defaultScore) > config.thresholds.aiGenerated,
      indicators: [
        ...(config.errorHandling.returnPartialResults ? statisticalAnalysis.indicators : []),
        {
          type: 'fallback_analysis',
          description: 'Analysis completed with limited capabilities due to API error',
          severity: 'low'
        }
      ],
      explanation: 'Analysis completed using statistical methods only due to API limitations. Results may be less accurate.',
      suspiciousParts: config.errorHandling.returnPartialResults ? statisticalAnalysis.suspiciousParts : [],
      processingTime: Date.now() - startTime,
      wordCount: metrics.wordCount,
      charCount: metrics.charCount
    }
  }
}

/**
 * Batch analysis for multiple texts (cost optimization)
 */
export async function batchDetectAI(texts: { text: string; language?: string }[]): Promise<(AIDetectionResult & { cost?: number })[]> {
  if (!config.costOptimization.enableBatching) {
    // Process sequentially if batching is disabled
    const results = []
    for (const { text, language = 'pt' } of texts) {
      results.push(await detectAIContent(text, language))
      // Add delay to respect rate limits
      await new Promise(resolve => setTimeout(resolve, config.rateLimiting.delayBetweenBatches))
    }
    return results
  }

  const results: (AIDetectionResult & { cost?: number })[] = []
  
  for (let i = 0; i < texts.length; i += config.rateLimiting.batchSize) {
    const batch = texts.slice(i, i + config.rateLimiting.batchSize)
    
    try {
      const batchResults = await Promise.all(
        batch.map(({ text, language = 'pt' }) => detectAIContent(text, language))
      )
      results.push(...batchResults)
    } catch (error) {
      if (config.monitoring.logErrors) {
        console.error(`Batch ${Math.floor(i / config.rateLimiting.batchSize) + 1} failed:`, error)
      }
      
      // Process batch items individually on failure
      for (const { text, language = 'pt' } of batch) {
        try {
          results.push(await detectAIContent(text, language))
        } catch (itemError) {
          if (config.errorHandling.enableFallback) {
            results.push({
              aiScore: config.errorHandling.defaultScore,
              confidence: 'LOW',
              isAiGenerated: false,
              indicators: [{
                type: 'analysis_failed',
                description: 'Analysis failed for this text',
                severity: 'low'
              }],
              explanation: 'Analysis failed due to technical issues',
              suspiciousParts: [],
              processingTime: 0,
              wordCount: text.split(/\s+/).length,
              charCount: text.length
            })
          }
        }
      }
    }
    
    // Add delay between batches to respect rate limits
    if (i + config.rateLimiting.batchSize < texts.length) {
      await new Promise(resolve => setTimeout(resolve, config.rateLimiting.delayBetweenBatches))
    }
  }
  
  return results
}

/**
 * Clear cache (useful for testing or memory management)
 */
export function clearAnalysisCache(): void {
  analysisCache.clear()
}

/**
 * Get cache statistics
 */
export function getCacheStats(): { 
  size: number; 
  entries: string[]; 
  maxEntries: number;
  expiryMinutes: number;
  enabled: boolean;
} {
  return {
    size: analysisCache.size,
    entries: Array.from(analysisCache.keys()),
    maxEntries: config.cache.maxEntries,
    expiryMinutes: config.cache.expiryMinutes,
    enabled: config.cache.enabled
  }
}

/**
 * Get daily cost statistics
 */
export function getDailyCostStats(): { date: string; cost: number; limit: number; remaining: number } {
  return {
    date: dailyCostTracker.date,
    cost: dailyCostTracker.cost,
    limit: config.costOptimization.maxDailyCost,
    remaining: config.costOptimization.maxDailyCost - dailyCostTracker.cost
  }
}

/**
 * Reset daily cost tracking (useful for testing)
 */
export function resetDailyCostTracking(): void {
  dailyCostTracker = { date: new Date().toDateString(), cost: 0 }
}

/**
 * Health check for AI detection system
 */
export async function healthCheck(): Promise<{
  status: 'healthy' | 'degraded' | 'down';
  checks: Record<string, boolean>;
  config: typeof config;
  errors: string[];
}> {
  const checks = {
    configValid: configValidation.isValid,
    apiKeyPresent: !!config.openai.apiKey,
    cacheWorking: true,
    costTrackingWorking: true
  }
  
  const errors = [...configValidation.errors]
  
  // Test cache
  try {
    const testKey = 'health_check_test'
    analysisCache.set(testKey, { test: true, timestamp: Date.now() })
    const retrieved = analysisCache.get(testKey)
    analysisCache.delete(testKey)
    checks.cacheWorking = !!retrieved
  } catch (error) {
    checks.cacheWorking = false
    errors.push('Cache is not working properly')
  }
  
  // Test cost tracking
  try {
    trackCost(0.001)
    checks.costTrackingWorking = true
  } catch (error) {
    checks.costTrackingWorking = false
    errors.push('Cost tracking is not working properly')
  }
  
  const healthyChecks = Object.values(checks).filter(Boolean).length
  const totalChecks = Object.keys(checks).length
  
  let status: 'healthy' | 'degraded' | 'down'
  if (healthyChecks === totalChecks) {
    status = 'healthy'
  } else if (healthyChecks > totalChecks / 2) {
    status = 'degraded'
  } else {
    status = 'down'
  }
  
  return {
    status,
    checks,
    config,
    errors
  }
}